epoch=1
	batch=0, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
	batch=500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=1000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.00
	batch=1500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
	batch=2000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.19
	batch=2500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
	batch=3000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=3374, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
training_loss=0.09, training_accuracy= 0.13
Validation: val_loss=0.09, val_accuracy=0.20
epoch=2
	batch=0, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.19
	batch=500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.19
	batch=1000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.00
	batch=1500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.31
	batch=2000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=2500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
	batch=3000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=3374, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
training_loss=0.09, training_accuracy= 0.22
Validation: val_loss=0.09, val_accuracy=0.20
epoch=3
	batch=0, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.19
	batch=500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.31
	batch=1000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.06
	batch=1500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.25
	batch=2000, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=2500, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
	batch=3000, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.25
	batch=3374, batch_loss=0.09, regularization_loss=0.00, total_batch_loss=0.09, batch_accuracy= 0.12
training_loss=0.09, training_accuracy= 0.23
Validation: val_loss=0.08, val_accuracy=0.21
epoch=4
	batch=0, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.12
	batch=500, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.38
	batch=1000, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.25
	batch=1500, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.38
	batch=2000, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.25
	batch=2500, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.25
	batch=3000, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.31
	batch=3374, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.31
training_loss=0.08, training_accuracy= 0.31
Validation: val_loss=0.08, val_accuracy=0.36
epoch=5
	batch=0, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.31
	batch=500, batch_loss=0.08, regularization_loss=0.00, total_batch_loss=0.08, batch_accuracy= 0.56
	batch=1000, batch_loss=0.07, regularization_loss=0.00, total_batch_loss=0.07, batch_accuracy= 0.50
Traceback (most recent call last):
  File "/home/sandip/Desktop/DL/Assignment 1/Test.py", line 104, in <module>
    model.train(X, y_train_one_hot, epochs=5, batch_size=16, validation_data=(X_val, y_val_one_hot), print_mini_batch=True,
  File "/home/sandip/Desktop/DL/Assignment 1/NN/Model.py", line 126, in train
    self.backward(output, batch_Y)
  File "/home/sandip/Desktop/DL/Assignment 1/NN/Model.py", line 89, in backward
    layer.backward(layer.next.grad_out)
  File "/home/sandip/Desktop/DL/Assignment 1/NN/Layer/Linear.py", line 48, in backward
    self.grad_out = np.dot(grad_in, self.weights.T)
  File "<__array_function__ internals>", line 5, in dot
KeyboardInterrupt
	batch=1500, batch_loss=0.07, regularization_loss=0.00, total_batch_loss=0.07, batch_accuracy= 0.56